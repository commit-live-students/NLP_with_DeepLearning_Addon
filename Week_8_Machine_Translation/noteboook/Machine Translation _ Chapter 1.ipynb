{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation\n",
    "\n",
    "Machine translation (MT) is automated translation. It is the process by which computer software is used to translate a text from one natural language (such as English) to another (such as Spanish). \n",
    "\n",
    "Until very recently, if you wanted to know the Chinese translation of an English sentence, you had to hire a linguist who would both know English and Chinese language and would then translate the english text into chinese. Problem solved. But what if you wanted to translate the same piece of text into 5 different languages ?\n",
    "\n",
    "In recent times, MT has become one of the hottest areas of research given the success it is getting using deep learning. We would have all used Google Translate at some point or the other. Researchers are devising new techniques which are getting them higher accuracy in translating from one language to another. Years of R&D in deep neural networks have resulted in advances in the field of Machine Translation using which we could translate a given piece of text to any language.\n",
    "\n",
    "This will be the main focus of this tutrial where different aspects of Machine translation will be presented on along with hands on tutorial to implement it yourself. So let's get right on to it.\n",
    "\n",
    "## Approaches\n",
    "\n",
    "Machine Translation(MT) has been an active area of studies right since the very beginnning of the computing age. Over the years it has evolved to what it is today. Some methods included pure semantic translation of the sentence / text based on some linguistic rules like replacing the words of the source language by the words of the target language. While, with the advent of latest search algorithms and big data, the process then shifted to Statistical based approaches. In the new era, with advances in Artificial Intelligence, MT has achived new heights and ever greater accuracy. Lets take a look at each of these processes in a bit more detail to better understand the journey of machine translation.\n",
    "\n",
    "   __1: Rule Based MT__: Rule based approach relies on countless built-in algorithms and sophisticated linguistic rules and millions of bi-lingual dictionaries of each language pair. The text would then be parsed and a transitional representation of the text would then be created, from which the final target text is generated. The translations are built on top of gigantic dictionaries having words from source and the target language thereby exponentially increasing the development cost and time. For example, let's say that we have to translate the following English text to German.\n",
    "   \n",
    "   __Source Language__ :English:  A girl eats an apple.\n",
    "   \n",
    "   __Target Language__: German\n",
    "   \n",
    "   According to Rule based MT, we need following to successfully translate the English text to German:\n",
    "   \n",
    "   1. A dictionary set, mapping each word in the English language to its German counterpart.\n",
    "   \n",
    "   2. Rules to represent English grammar\n",
    "   \n",
    "   3. Rules to represent German grammar.\n",
    "   \n",
    "   4. Rules relating English grammar to German grammar.\n",
    "   \n",
    "   \n",
    "   So using the above rules, we can attempt to translate the text to German in following stages:-\n",
    "   \n",
    "   __Stage 1__:\n",
    "      Get POS(Parts of speech) information.\n",
    "      \n",
    "      `a` article, `girl` noun, `eats` verb, `an` article, `apple` noun\n",
    "      \n",
    "   __Stage 2__:\n",
    "       \n",
    "      Then translate into German text by dictionary lookup and rules of grammar\n",
    "      \n",
    "      `a` = `ein`\n",
    "      \n",
    "      `girl` = `Madchen`\n",
    "      \n",
    "      `eat` = `essen`\n",
    "      \n",
    "      `apple` = `Apfel`\n",
    "      \n",
    "      So the translation would look something like :\n",
    "      \n",
    "      `A girl eats an apple` => `Ein Madchen isst einen Apfel`\n",
    "      \n",
    "    \n",
    "    We usually use Rule based MT methodologies for translating trivial sentences from one language to another where in the grammatical and syntactical rule sets are predefined in the system and all that's done is refer to the rule book and convert to the target language.\n",
    "    \n",
    "   __2: Statistical MT__: Statistical MT tries to generate translations using statistical methods bases on bilingual text corpora. A document is converted according to probablity distribution $p(e|f)$ that a string $e$ in the target language, for example English is the translation of a string $f$ in the source language (for example, French). \n",
    "   \n",
    "   Typically in Statistical MT models, sentences are translated at once. A bilingual text corpus is trained and translated into probablity functions, like Bayes Theorem, where the translation model depicts a probablity function which estimates the probablity of a source string being a translation of the target string(from the dictionary).\n",
    "   \n",
    "   __Limitations__:\n",
    "   * The accuracy of this approach is directly proportional to the availability of the corpus of the language pair. The constraint here is the limited availability of such corpora for many language pairs thus limiting major success using the Statistical method.\n",
    "   \n",
    "   * Corpus training and creation can be really costly\n",
    "   \n",
    "   * Some errors can be hard to predict and fix.\n",
    "   \n",
    "   __Other statistical based approaches:__\n",
    "   \n",
    "   __2.1: Word based MT__: In word based MT, the fundamental unit of translation is a word. So each word of the source language is mapped on to one or more word of the target language. And then, a probablity function determines the best word(from the target language) to repressent the word from the source lang. However, the number of words in the translatd sentence can differ since a word in source language may tranlate to one or more words in the target language. To have a standard statistical measurement for this, a measure of ration of lengths of sequences of translated words called __fertility__ was introduced. It basically tells how many target language words, a source language word produces. It was assumed from the principles of Information theory that each of these words would cover the same concept. In practise however, this was not really true. For example, the English word corner can be translated in Spanish by either rincÃ³n or esquina, depending on whether it is to mean its internal or external angle.\n",
    "   \n",
    "   Let us try and understand this with a more concrete example. In what follows we will try to translate a German text into English.\n",
    "   Haus (German) -> house, building, home, household, shell(The house of a snail is shell)\n",
    "   \n",
    "   Now we see here that 1 german word has multiple english word translation based on the context of usage etc. Using statistical MT based approach, we will find out the word with the hightst probablity in the corpus(as shown in the figure below)\n",
    "   \n",
    "   <img src=\"../images/wordbasedmt.png\"/>\n",
    "\n",
    "\n",
    "Now when we look at the maximum likelihood score of the above words,\n",
    "\n",
    "<img src=\"../images/probablity_wordmt.png\"/>\n",
    "\n",
    "So we choose \"house\" as the probable translation to the word \"Haus\". Similarly we translate all the other words in source text (German) to target text (English):-\n",
    "\n",
    "<img src=\"../images/wt.png\"/>\n",
    "\n",
    "   __2.2: Phrase Based MT__: Phrase based models adopt a similar way of translation as Word based MT, the difference being, in Word based MT, the atomic unit is a word, whereas in Phrase based MT, the atomic unit is a phrase.\n",
    "Source text is split into phrases and then each phrase is then translated into the target language.  \n",
    "\n",
    "Let's try and understand this with an example. Let us consider the following source text(German):\n",
    "\n",
    "<img src=\"../images/phrasemt1.png\"/>\n",
    "\n",
    "As you can see in the figure above, the foreign text is segmented into phrases. Now similar to Word based translation, maximum likelihood score for the phrases will be calculated from the corpus and each of the probable phrases in the target language (English) will be assigned a score. The phrase with the best score would then be selected.\n",
    "\n",
    "For example, for the phrase translation of the word \"natuerlich\", the probablity scores could be something like :\n",
    "\n",
    "<img src=\"../images/phrasemt2.png\"/>\n",
    "\n",
    "Similarly the scores for each of the phrases would be calculated and then the translation to the target language would be the output as shown in the following:\n",
    "\n",
    "<img src=\"../images/phrasemt3.png\"/>\n",
    "\n",
    "   __3: Neural Machine Translation__: Neural MT takes advantage of the advances in deep learning in the world today and attempts to mitigate the shortcomings of other machine translation approaches that we studied earlier. It has been observed that it is able to produce better results with greator accuracy and with requirement of less data. Infact, many popular neural based machine translation do not need any inputs regarding grammar, rules of the language etc(unlike rule based / statistical machine translation).\n",
    "   \n",
    "Many of the popular neural MT approaches use a framework called Encoder-Decoder framework, in which the source language is encoded into an intermediatory machine generated language and is then decoded by another Decoder layer. This approach has proved to be very efficient in generating translations with very high accuracy and is currently the industry adopted approach for machine translation. We will be studying this is greator detail in the next few chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
